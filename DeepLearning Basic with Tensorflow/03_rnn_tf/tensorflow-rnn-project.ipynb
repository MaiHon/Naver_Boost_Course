{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"목차","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"349.091px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"tensorflow-rnn-project.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NH-oVIBvSKB7","colab_type":"text"},"source":["# Colab 사용자를 위한 안내\n","\n","해당 노트북은 **로컬** 환경에서 최적화 되어 있습니다. 로컬 환경에서 진행하시는 분들은 바로 학습을 진행하시면 됩니다.\n","\n","Colab 을 사용하시는 분들은 처음에 아래 주석을 해제하시고 한번 만 실행시켜주세요!\n","\n","* 주석을 해제하는 방법: 해당 영역을 선택하고, `Ctrl + /` 를 누르면 해당 영역의 주석에 해제됩니다."]},{"cell_type":"code","metadata":{"id":"GgwXxsQmSKB-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"778323af-c3b2-4959-f5ba-686165771a26","executionInfo":{"status":"ok","timestamp":1579281413205,"user_tz":-540,"elapsed":4806,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iZggKaKISKCB","colab_type":"text"},"source":["Colab 을 사용하시는 분들은 아래 주석을 해제하시고 `folder` 변수 명에 프로젝트 디렉토리를 저장한 위치를 작성해주세요! 예를 들어, `03_rnn_tf` 의 위치가 \"내 드라이브 > colab_notebook > tensorflow\" 폴더 안에 있는 경우, \"colab_notebook/tensorflow\" 를 작성하시면 됩니다.\n","\n","```python\n","folder = \"colab_notebook/tensorflow\"\n","```"]},{"cell_type":"code","metadata":{"id":"YdLDuI3xSKCC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"77d2f354-f314-4544-ac49-92865216d9c8","executionInfo":{"status":"ok","timestamp":1579281413206,"user_tz":-540,"elapsed":4797,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["import os\n","from pathlib import Path\n","\n","# folder 변수에 구글드라이브에 프로젝트를 저장한 디렉토리를 입력하세요!\n","folder = \"Colab Notebooks/tensorflow/\"\n","project_dir = \"03_rnn_tf\"\n","\n","base_path = Path(\"/content/gdrive/My Drive/\")\n","project_path = base_path / folder / project_dir\n","os.chdir(project_path)\n","for x in list(project_path.glob(\"*\")):\n","    if x.is_dir():\n","        dir_name = str(x.relative_to(project_path))\n","        os.rename(dir_name, dir_name.split(\" \", 1)[0])\n","print(f\"현재 디렉토리 위치: {os.getcwd()}\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["현재 디렉토리 위치: /content/gdrive/My Drive/Colab Notebooks/tensorflow/03_rnn_tf\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9AgUnOmbSKCD","colab_type":"text"},"source":["TensorFlow 는 `1.14.0` 버전을 기준으로 합니다. Colab 사용시, 첫번째 코드를 실행해보시고 만약에 버전이 다르다면 두 번째 주석을 해제하고 실행해주세요."]},{"cell_type":"code","metadata":{"id":"yz1IldoBSKCE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":508},"outputId":"0b8bbc17-d8fd-43da-e439-6402e49f6e1f","executionInfo":{"status":"ok","timestamp":1579281413881,"user_tz":-540,"elapsed":5462,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["import tensorflow as tf\n","print('tensorflow version: {}'.format(tf.__version__))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["tensorflow version: 1.14.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"45eoDbGoSKCH","colab_type":"code","colab":{}},"source":["# !pip install tensorflow-gpu==1.14.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uImb7wwpSKCJ","colab_type":"text"},"source":["# Recurrent Neural Network: Neural Weather Forecaster\n","\n","<img src=\"http://drive.google.com/uc?export=view&id=139sr_X8Hi8O8s43syKDxW7UCF33X_mjh\" width=\"600px\" height=\"800px\" />\n","\n","* 이미지 출처: 네이버\n","\n","많은 사람이 아침에 집을 나서기 전에 오늘 기온이 어떤지 혹은 비가 오는지 알기 위해 일기예보를 확인합니다. 그런데 혹시 일기예보가 어떻게 이루어지는지 생각해 보신적이 있으신가요? 아직 오지도 않은 미래의 날씨를 어떻게 예측할 수 있을까요? 아마 여러분 대부분은 기상 예측과 관련된 전문적인 지식에 대해 잘 알지 못할 것입니다. 엄청난 계산능력을 갖춘 슈퍼컴퓨터가 복잡한 계산을 통해 예측을 한다는 정도는 들어보신 분들도 계실 수 있겠네요. 하지만 딥러닝을 활용할 수 있고, 지난 과거의 기후 데이터만 가지고 있으면 여러분의 PC에서도 훌륭한 일기예보 모델을 학습시킬 수 있습니다. 이번 프로젝트에서는 RNN을 직접 설계하여 24시간 후의 기온을 예측하는 문제를 해결할 것입니다.\n","\n","\n","이번 실습의 목표는 다음과 같습니다.\n","- RNN을 설계하여 지난 며칠 동안의 날씨 정보를 기반으로 24시간 이후의 기온을 예측한다.\n","- 다양한 속성의 시계열 정보를 활용하기 위해 적절한 전처리 과정을 적용한다. \n","- 설계한 모델의 성능을 검증하기 위해 베이스라인 모델을 도입한다.\n","\n","실습코드는 Python 3.6, TensorFlow 1.14.0 버전을 기준으로 작성되었습니다.\n","\n","이번 과정을 통해 얻는 최종 결과물은 아래 그림과 같습니다.\n","\n","<img src=\"http://drive.google.com/uc?export=view&id=1UD4n1qLY2o3ayAQq-LOOiHd76qiCVAYk\" width=\"600px\" height=\"400px\" />\n","<center>&lt;기온, 강수량 등 다양한 정보로 미래의 기온 예측&gt;</center></caption>\n","\n","### 이제부터 본격적으로 프로젝트를 시작하겠습니다.\n","\n","**\"[TODO] 코드 구현\"** 부분의 **\"## 코드 시작 ##\"** 부터 **\"## 코드 종료 ##\"** 구간에 필요한 코드를 작성해주세요. **나머지 작성구간이 명시 되지 않은 구간은 임의로 수정하지 마세요!**\n","\n","**본문 중간중간에 TensorFlow 함수들에 대해 [TensorFlow API 문서](https://www.tensorflow.org/api_docs/python/tf) 링크를 걸어두었습니다. API 문서를 직접 확인하는 일에 익숙해지면 나중에 여러분이 처음부터 모델을 직접 구현해야 할 때 정말 큰 도움이 됩니다.**"]},{"cell_type":"markdown","metadata":{"toc":true,"id":"--2x0h9WSKCK","colab_type":"text"},"source":["<h1>목차<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Colab-사용자를-위한-안내\" data-toc-modified-id=\"Colab-사용자를-위한-안내-1\">Colab 사용자를 위한 안내</a></span></li><li><span><a href=\"#Recurrent-Neural-Network:-Neural-Weather-Forecaster\" data-toc-modified-id=\"Recurrent-Neural-Network:-Neural-Weather-Forecaster-2\">Recurrent Neural Network: Neural Weather Forecaster</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Package-load\" data-toc-modified-id=\"1.-Package-load-2.1\">1. Package load</a></span></li><li><span><a href=\"#2.-하이퍼파라미터-세팅\" data-toc-modified-id=\"2.-하이퍼파라미터-세팅-2.2\">2. 하이퍼파라미터 세팅</a></span></li><li><span><a href=\"#3.-데이터-전처리-함수-정의\" data-toc-modified-id=\"3.-데이터-전처리-함수-정의-2.3\">3. 데이터 전처리 함수 정의</a></span></li><li><span><a href=\"#4.-데이터-샘플-시각화\" data-toc-modified-id=\"4.-데이터-샘플-시각화-2.4\">4. 데이터 샘플 시각화</a></span></li><li><span><a href=\"#5.-Dataset-만들기\" data-toc-modified-id=\"5.-Dataset-만들기-2.5\">5. Dataset 만들기</a></span></li><li><span><a href=\"#6.-베이스라인-성능-측정\" data-toc-modified-id=\"6.-베이스라인-성능-측정-2.6\">6. 베이스라인 성능 측정</a></span></li><li><span><a href=\"#7.-네트워크-설계\" data-toc-modified-id=\"7.-네트워크-설계-2.7\">7. 네트워크 설계</a></span></li><li><span><a href=\"#8.-Loss-function,-Optimizer-정의\" data-toc-modified-id=\"8.-Loss-function,-Optimizer-정의-2.8\">8. Loss function, Optimizer 정의</a></span></li><li><span><a href=\"#9.-train,-validation,-test-함수-정의\" data-toc-modified-id=\"9.-train,-validation,-test-함수-정의-2.9\">9. train, validation, test 함수 정의</a></span></li><li><span><a href=\"#10.-Training\" data-toc-modified-id=\"10.-Training-2.10\">10. Training</a></span></li><li><span><a href=\"#11.-저장된-모델-불러오기-및-test\" data-toc-modified-id=\"11.-저장된-모델-불러오기-및-test-2.11\">11. 저장된 모델 불러오기 및 test</a></span></li><li><span><a href=\"#12.-Summary\" data-toc-modified-id=\"12.-Summary-2.12\">12. Summary</a></span></li></ul></li><li><span><a href=\"#Self-Review\" data-toc-modified-id=\"Self-Review-3\">Self-Review</a></span></li></ul></div>"]},{"cell_type":"markdown","metadata":{"id":"eS39tIXGSKCK","colab_type":"text"},"source":["## 1. Package load\n","\n","필요한 패키지들을 로드합니다."]},{"cell_type":"code","metadata":{"id":"eOcp4m31SKCL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"de9f7b36-5357-411d-eec8-f73928ac8154","executionInfo":{"status":"ok","timestamp":1579281413882,"user_tz":-540,"elapsed":5443,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","from __future__ import unicode_literals\n","\n","from tensorflow.keras import layers\n","import tensorflow as tf\n","import check_util.checker as checker\n","from IPython.display import clear_output\n","import os\n","import time\n","import glob\n","import csv\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","tf.enable_eager_execution()\n","print('tensorflow version: {}'.format(tf.__version__))\n","print('GPU 사용 가능 여부: {}'.format(tf.test.is_gpu_available()))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tensorflow version: 1.14.0\n","GPU 사용 가능 여부: True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qc9rP9UPSKCN","colab_type":"text"},"source":["## 2. 하이퍼파라미터 세팅\n","\n","학습에 필요한 하이퍼파리미터의 값을 초기화해줍니다.\n","\n","미니배치의 크기(`batch_size`), 학습 할 epoch 수(`max_epochs`), 학습률(`learning_rate`) 등의 값들을 다음과 같이 정합니다."]},{"cell_type":"code","metadata":{"id":"fNV9b-FlSKCO","colab_type":"code","colab":{}},"source":["batch_size = 128\n","max_epochs = 30\n","learning_rate = 3e-5\n","hidden_sizes = [100, 100]  # hidden_sizes must be a list"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-LShUI9rSKCQ","colab_type":"text"},"source":["## 3. 데이터 전처리 함수 정의\n","\n","우리는 이번 실습에서 지난 10년간의(2009년~2018년) 서울시 기후 데이터를 활용해 기온을 예측하는 모델을 학습시킬 것입니다. 데이터셋은 [기상자료개방포털](https://data.kma.go.kr/)에서 받은 자료입니다. 이번 실습에서 사용하는 데이터 이외에도 기상자료개방포털에서 기상과 관련된 다양한 자료들을 내려받으실 수 있습니다. \n","\n","`./data/climate_seoul` 경로의 디렉토리를 보시면, `test` / `train` / `val` 디렉토리에 csv파일이 각각 1개 / 8개/ 1개 담겨있음을 확인하실 수 있습니다. 각 csv파일은 1년간의 서울시 기후 데이터를 담고 있으며, 1시간 간격으로 기록된 정보입니다. (사실 아주 가끔씩 30분 간격으로 기록한 구간도 있기도 하지만, 이후 본문에서는 편의상 모두 1시간 간격으로 기록된 것으로 간주하겠습니다.) 매 시간마다 기록되는 정보는 기온, 강수량, 풍속 등을 포함한 총 25가지 속성으로 이루어져 있습니다. 이 중에서 우리는 기온, 강수량, 풍속, 습도, 증기압을 포함한 총 9가지의 속성만을 사용하여 기온 예측 모델을 학습시켜 보겠습니다.\n","\n","그렇다면 왜 하필 이 9가지의 속성을 선택한 것일까요? 이렇게 9가지의 속성을 선택한 배경에는 어떠한 전문적인 지식도 고려되지 않은 것입니다. 25가지의 속성을 모두 사용해볼 수도 있겠죠. 어떤 속성들을 활용할지는 설계자의 몫입니다. 그런데 여러분이 기상과 관련된 전문적인 지식을 갖고 있지 않는 이상 이중에서 어떤 속성이 기온 예측에 가장 중요한지, 또는 어떤 속성이 가장 불필요한 속성인지 알지 못할 것입니다. 하지만 고맙게도 딥러닝은 이러한 속성 선택 문제에 덜 예민한 학습 방식입니다. 더 정확하게 말하면, 다소 불필요한 정보가 입력으로 주어진다고 해서 극단적으로 학습이 이루어지지 않는 일은 일어나지 않을 가능성이 큽니다. 학습과정에서 인공신경망이 필요한 특징(feature)을 알아서 추출하기 때문입니다. 그러니까 우리는 어떤 속성을 활용할지를 너무 심각하게 고민하지 않아도 되는 것입니다. 다만 이번 실습에서는 매번 빠짐없이 잘 기록된 속성들을 위주로 9가지를 선택한 것 뿐입니다.\n","\n","아래에 정의한 전처리 `preprocess` 함수는 csv파일들을 읽어 9가지 속성 정보만을 NumPy 배열에 저장해 반환하는 역할을 합니다. 이 함수는 이후에 `train_data`, `val_data`, `test_data`를 구현할 때 활용될 것입니다."]},{"cell_type":"code","metadata":{"id":"2Ue5KngJSKCR","colab_type":"code","colab":{}},"source":["def preprocess(all_files):\n","    data_0 = []  # 기온\n","    data_1 = []  # 강수량\n","    data_2 = []  # 풍속\n","    data_3 = []  # 습도\n","    data_4 = []  # 증기압\n","    data_5 = []  # 이슬점 온도\n","    data_6 = []  # 현지 기압\n","    data_7 = []  # 해면 기압\n","    data_8 = []  # 지면 온도\n","    for f in all_files:\n","        with open(f, encoding='euc-kr') as c:\n","            csv_reader = csv.reader(c, delimiter=',')\n","            header = True\n","            for col in csv_reader:\n","                if header:\n","                    header = False\n","                    continue\n","                data_0.append(\n","                    float(col[2])) if col[2] != '' else data_0.append(0.0)\n","                data_1.append(\n","                    float(col[3])) if col[3] != '' else data_1.append(0.0)\n","                data_2.append(\n","                    float(col[4])) if col[4] != '' else data_2.append(0.0)\n","                data_3.append(\n","                    float(col[6])) if col[6] != '' else data_3.append(0.0)\n","                data_4.append(\n","                    float(col[7])) if col[7] != '' else data_4.append(0.0)\n","                data_5.append(\n","                    float(col[8])) if col[8] != '' else data_5.append(0.0)\n","                data_6.append(\n","                    float(col[9])) if col[9] != '' else data_6.append(0.0)\n","                data_7.append(\n","                    float(col[10])) if col[10] != '' else data_7.append(0.0)\n","                data_8.append(\n","                    float(col[22])) if col[22] != '' else data_8.append(0.0)\n","\n","    data = np.zeros((len(data_0), 9))\n","    for i, d in enumerate(data):\n","        data[i, 0] = data_0[i]\n","        data[i, 1] = data_1[i]\n","        data[i, 2] = data_2[i]\n","        data[i, 3] = data_3[i]\n","        data[i, 4] = data_4[i]\n","        data[i, 5] = data_5[i]\n","        data[i, 6] = data_6[i]\n","        data[i, 7] = data_7[i]\n","        data[i, 8] = data_8[i]\n","\n","    return data.astype(np.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5jrzYb-_SKCU","colab_type":"text"},"source":["**preprocess**를 해주고 나면, 데이터가 다음 그림과 같이 매 시간마다 총 9가지의 속성만 저장됩니다.\n","\n","<img src=\"http://drive.google.com/uc?export=view&id=1iA_SHcfJ9XnZ2w_S66GS_XpvRH7WNXGf\" width=\"600px\" height=\"400px\" />"]},{"cell_type":"code","metadata":{"id":"zjYPyQLISKCV","colab_type":"code","colab":{}},"source":["data_dir = './data/climate_seoul'\n","\n","train_data = preprocess(sorted(glob.glob(os.path.join(data_dir, 'train', '*'))))\n","val_data = preprocess(sorted(glob.glob(os.path.join(data_dir, 'val', '*'))))\n","test_data = preprocess(sorted(glob.glob(os.path.join(data_dir, 'test', '*'))))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lYHKn5raSKCY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"92a8f171-d441-4b51-a3af-a300d9fc695a","executionInfo":{"status":"ok","timestamp":1579281414896,"user_tz":-540,"elapsed":6424,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["print(\"shape of train data: {}\".format(train_data.shape))\n","print(\"shape of val data: {}\".format(val_data.shape))\n","print(\"shape of test data: {}\".format(test_data.shape))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["shape of train data: (70133, 9)\n","shape of val data: (8760, 9)\n","shape of test data: (8760, 9)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D7hP_2CqSKCa","colab_type":"text"},"source":["## 4. 데이터 샘플 시각화\n","\n","`train_data`의 첫번째 `column` 즉 온도 데이터를 그래프 형태로 시각화합니다.\n","\n","$\\Delta t = 240$: 240시간, 즉 10일 동안의 온도 그래프를 그려봅니다. 그림을 보면 10개의 주기적으로 나타나는 뽀죡한 고 점들을 볼 수 있는데 이 점들이 하루의 낮 최고 기온을 의미하는 것으로 보입니다. "]},{"cell_type":"code","metadata":{"id":"ZnUklC3pSKCb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":279},"outputId":"d1c04d46-9d29-487d-f8bd-644410389b36","executionInfo":{"status":"ok","timestamp":1579281414897,"user_tz":-540,"elapsed":6415,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["start = 0\n","dt = 240\n","plt.plot(train_data[start:start+dt, 0])\n","plt.ylabel(\"temperature\")\n","plt.xlabel(\"time-delta\")\n","plt.show()"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY8AAAEGCAYAAACdJRn3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvSx8WVDfAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"srIcxO7aSKCc","colab_type":"text"},"source":["## 5. Dataset 만들기\n","\n","이제 우리가 사용할 데이터셋에 대해 정의할 차례입니다. 이를 위해  `make_dataset` 함수를 만들 것이며 여기서 사용되는 각 인수의 의미는 다음과 같습니다.\n","\n","- `data`: **<3. 데이터 전처리 함수 정의>** 에서 정의한 전처리 `preprocess` 함수로 얻은 `train_data`, `val_data`, `test_data` 가 됩니다. `data`의 shape은 (데이터의 총 길이, 9)가 됩니다.\n","- `seq_length`: 우리가 이후에 설계할 RNN의 입력으로 줄 데이터 시퀀스의 길이, 즉 총 타임스텝의 길이를 뜻합니다. 다시 말하면, 현재로부터 24시간 뒤의 기온을 예측하기 위해 얼마만큼의 과거 정보를 참고할지 결정하는 것입니다. 기본값을 480로 해두었는데, 이는 480개의 과거 데이터를 살펴보겠다는 것이고, 데이터 1개는 1시간마다 기록되기 때문에 결과적으로 지난 20일간의 데이터를 기반으로 24시간 후의 기온을 예측하겠다는 의미입니다.\n","- `target_delay`: 우리가 예측할 시점이 입력 시퀀스의 마지막 타임스텝으로 얼만큼 이후인지 결정하는 것입니다. 24로 기본값을 해두었고, 이는 24시간 이후의 기온이 우리가 예측할 대상임을 의미하는 것입니다. 예를 들어 1월 1일 00:00 부터 1월 21 일 23:00 까지 480 개의 데이터를 이용한다면 예측 데이터는 1월 21일 23:00 로부터 24 시간 후인 1월 22일 23:00 시점의 기온입니다.\n","- `strides`: 학습할 데이터의 양을 조절하기 위해 만든 옵션 입니다. $\\Delta t = 10$, `strides=1`이라고 할 때 $\\mathbf{x}^{(1)} = [x_{1}, x_{2}, \\cdots, x_{10}]$, $\\mathbf{x}^{(2)} = [x_{2}, x_{3}, \\cdots, x_{11}]$, $\\mathbf{x}^{(3)} = [x_{3}, x_{4}, \\cdots, x_{12}]$ 이런식으로 데이터를 사용합니다. 우리가 사용하는 데이터의 time step이 많기 때문에 `strides=1`이면 굉장히 많은 수의 training data를 가질 수 있습니다. gpu가 없거나 빠른 테스트를 위한다면 `strides`를 조절하여 데이터 양을 조절하면 좋을 것 같습니다. 예를들어 `strides=3`이면 $\\mathbf{x}^{(1)} = [x_{1}, x_{2}, \\cdots, x_{10}]$, $\\mathbf{x}^{(2)} = [x_{4}, x_{5}, \\cdots, x_{13}]$, $\\mathbf{x}^{(3)} = [x_{7}, x_{8}, \\cdots, x_{16}]$ 이와 같이 sampling을 하여 데이터를 사용합니다.\n","<img src=\"http://drive.google.com/uc?export=view&id=1DJ6lybrsRD8D8TtHBvbo-DU7zi-U4JMm\"  width=\"800px\" height=\"300px\" />\n","- `mode`: `train`, `val`, `test`를 뜻합니다.\n","- `train_mean`, `train_std`: 입력으로 사용하는 데이터의 각 속성은 저마다 값의 범위가 다릅니다. 예를 들어 기온은 보통 -15에서 35사이의 값을 갖지만, 강수량과 풍속은 음수 값이 존재하지 않고, 기압의 경우에는 1000 내외의 값이 일반적입니다. 이러한 경우 각각의 속성들을 저마다의 평균과 표준편차를 통해 값을 정규화(normalize)해주는 것이 바람직합니다. 정규화 시 `train`, `val`, `test` 각각의 데이터셋에 대해서 진행하는 것이 아니라 `train` 데이터 셋에서 구한 평균인 `train_mean`과 표준편차인 `train_std`를 이용하여 `val`, `test` 데이터 셋을 정규화해야 합니다."]},{"cell_type":"markdown","metadata":{"id":"STlwYrSlSKCd","colab_type":"text"},"source":["### <font color='red'>[TODO] 코드 구현</font>\n","\n","이제 다음을 읽고 코드를 완성해보세요.\n","1. `mode`에 맞게 정규화(normalize) 코드를 작성해보세요.\n","    - 1-1 : `train` 모드일 때: `train` 디렉토리에 있는 데이터 셋의 `mean`, `std`를 구해야 합니다. 함수를 사용할 경우 `axis`를 주의해 주세요.\n","    - 1-2 : `val` 또는 `test` 모드일 때: `train_mean`, `train_std`를 이용합니다.\n","    - 1-3 : normalize 코드를 작성해보세요. (수식은 다음과 같습니다.)\n","        - $ (X - \\mathbb{E}(X)) \\, / \\, \\sqrt{ \\mathrm{Var} (X) } $.\n","        - $\\mathbb{E}(X)$ 는 데이터의 평균, $\\sqrt{ \\mathrm{Var} (X) }$ 는 데이터의 표준편차입니다.\n","2. `for`문으로 전체 타임스텝 (`range(len(data) - seq_length - target_delay)`)을 돌면서 인덱스(변수명 `index`)가 `stride`로 나누어 떨어질 때만 훈련 데이터 셋으로 저장을 합니다.\n","    - 2-1 : `stride=3` 이면 `index`가 0, 3, 6, 9, ... 일 때만 `sequence`와 `target`에 데이터를 집어넣는 것입니다. 즉 해당 인덱스는 각 배치 데이터의 첫번째 인덱스가 됩니다. 따라서 `data` 변수에 해당하는 데이터를 `index`부터 `seq_length`(480시간)만큼 잘라내어 `sequence`에 추가합니다. 이는 곧 모델에게 전달되는 입력 데이터가 됩니다.\n","    - 2-2 : `data`의 `index`부터 `seq_length`만큼의 떨어진 위치에서 다시 `target_delay`(즉 24시간) 만큼 떨어진 위치의 기온(0번째 컬럼)을 target에 추가합니다.\n","3. 최종 Numpy로 변경되었을때 `sequence`의 shape은 (N, `seq_length`, 9), `target`의 shape은 (N,)이 되어야 합니다. N은 전체 데이터 갯수 입니다.\n","\n","**make_dataset 함수 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"-FDvU8h0SKCe","colab_type":"code","colab":{}},"source":["def make_dataset(data, seq_length=480, target_delay=24, strides=5,\n","                 mode='train', train_mean=None, train_std=None):\n","    '''\n","        각 인수에 대한 설명은 위의 'Dataset만들기' 설명을 참고하세요.\n","    '''\n","    assert mode in ['train', 'val', 'test']\n","    if mode is not 'train':\n","        if train_mean is None or train_std is None:\n","            print('Current mode is {}'.format(mode))\n","            print('This mode needs mean and std of train data')\n","            assert False\n","\n","    # 정규화\n","    ## 코드 시작 ##\n","    if mode is 'train':\n","        mean = np.mean(data, axis=0)    # 위의 설명 1-1 을 참고하여 None을 채우세요.\n","        std = np.std(data, axis=0)     # 위의 설명 1-1 을 참고하여 None을 채우세요.\n","    else: \n","        mean = train_mean    # 위의 설명 1-2 를 참고하여 None을 채우세요.\n","        std = train_std     # 위의 설명 1-2 를 참고하여 None을 채우세요.\n","    data = (data-mean)/std        # 위의 설명 1-3 을 참고하여 None을 채우세요.\n","    ## 코드 종료 ##\n","    \n","    # 입력, 타겟 데이터 생성\n","    sequence = []\n","    target = []\n","    for index in range(len(data) - seq_length - target_delay):\n","        if index % strides == 0:\n","            ## 코드 시작 ##\n","            sequence.append(data[index:index+seq_length])    # 위의 설명 2-1 을 참고하여 None을 채우세요.\n","            target.append(data[index+seq_length:index+seq_length+target_delay][-1][0])      # 위의 설명 2-2 를 참고하여 None을 채우세요.\n","            ## 코드 종료 ##\n","\n","    if mode is 'train':\n","        return np.array(sequence), np.array(target), mean, std\n","    else:\n","        return np.array(sequence), np.array(target)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDWPRyEgSKCi","colab_type":"text"},"source":["이제 학습용, 검증용, 테스트용 dataset을 만들어 봅니다."]},{"cell_type":"code","metadata":{"id":"IBaSZ-wySKCi","colab_type":"code","colab":{}},"source":["seq_length = 480\n","target_delay = 24\n","strides = 5\n","train_sequences, train_labels, train_mean, train_std = make_dataset(\n","    train_data, seq_length, target_delay, strides, mode='train')\n","val_sequences, val_labels = make_dataset(\n","    val_data, seq_length, target_delay, strides, mode='val', train_mean=train_mean, train_std=train_std)\n","test_sequences, test_labels = make_dataset(\n","    test_data, seq_length, target_delay, strides, mode='test', train_mean=train_mean, train_std=train_std)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"shDAmmVaSQwL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"a6ff9e04-829a-4ab6-817e-36cacdc11718","executionInfo":{"status":"ok","timestamp":1579281415345,"user_tz":-540,"elapsed":6825,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["print(train_sequences.shape)\n","print(train_labels.shape)\n","print(train_mean.shape)\n","print(train_std.shape)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(13926, 480, 9)\n","(13926,)\n","(9,)\n","(9,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U2FmkUmKSKCk","colab_type":"text"},"source":["#### Input pipeline 만들기\n","\n","`tf.data.Dataset`을 이용하여 `train`, `val`, `test`의 input pipeline 구축합니다.\n","* `tf.data.Dataset.from_tensor_slices`: `numpy`타입(또는 리스트 형태의 데이터)의 데이터를 `tf.data.Dataset`포맷의 데이터로 변환시켜줍니다.\n","* `tf.data.Dataset.shuffle`: 데이터셋을 shuffle 시켜줍니다.\n","* `tf.data.Dataset.batch`: 데이터셋의 batch_size를 결정합니다."]},{"cell_type":"code","metadata":{"id":"-dfIJIeJSKCl","colab_type":"code","colab":{}},"source":["# shuffle의 인자로 buffer_size가 필요한데 이는 전체 데이터셋 갯수로 하는게 좋습니다.\n","N = BUFFER_SIZE = len(train_sequences)  # number of samples in train_dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices(\n","    (train_sequences, train_labels))\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.batch(batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iyMt0_h7SKCn","colab_type":"text"},"source":["`val`, `test`데이터 셋은 shuffle할 필요가 없습니다. \n","* `train`시 shuffle하는 목적은 mini-batch gradient descent를 하기 위해 mini-batch 데이터를 random 하게 뽑는 것입니다. \n","* `val`, `test` 데이터 셋의 목적은 모든 데이터셋을 다 보고 성능을 평가하기 위함입니다. 그렇기 때문에 `val`, `test`데이터 셋은 shuffle할 필요가 없습니다."]},{"cell_type":"code","metadata":{"id":"kusJjGY8SKCn","colab_type":"code","colab":{}},"source":["# val_dataset\n","val_dataset = tf.data.Dataset.from_tensor_slices((val_sequences, val_labels))\n","val_dataset = val_dataset.batch(batch_size)\n","\n","# test_dataset\n","test_dataset = tf.data.Dataset.from_tensor_slices(\n","    (test_sequences, test_labels))\n","test_dataset = test_dataset.batch(batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUR-gnQMSKCp","colab_type":"text"},"source":["아래의 코드를 실행해 코드를 성공적으로 완성했는지 확인해보세요. \n","\n","별다른 문제가 없다면 이어서 진행하면 됩니다."]},{"cell_type":"code","metadata":{"id":"eND8tWU0SKCp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a3a4dfc4-4a00-4a3c-f851-d20bd84bef42","executionInfo":{"status":"ok","timestamp":1579281416013,"user_tz":-540,"elapsed":7469,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["checker.customized_dataset_check(train_sequences, train_labels, train_dataset, train_mean, train_std, seq_length, target_delay, strides)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["tf.data.Dataset을 잘 구현하셨습니다! 이어서 진행하셔도 좋습니다.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9oR_efizSKCr","colab_type":"text"},"source":["## 6. 베이스라인 성능 측정\n","\n","이후에 우리가 학습시킨 모델의 성능의 좋고 나쁨을 판단할 기준(베이스라인)이 필요합니다. 적당한 수준의 기준 성능을 정해놓고 테스트 결과에서 우리의 모델이 그것보다 더 좋은 성능을 보이면 만족할만한 모델을 학습시킨 것으로 간주하면 되고, 반대로 그보다 성능이 좋지 않다면 모델을 더 개선시키는 방식으로 네트워크 구조를 변경해 나아가면 됩니다.\n","\n","과거의 기후 정보를 활용하는 우리의 딥러닝 모델이 과연 의미있는 성능이라는 걸 보이기 위해서는 어떠한 예측 방식이 기준이 될 수 있을까요? 아마 기온 예측 전문가가 아닌 대부분의 여러분이 지금으로부터 24시간 후의 기온을 예측하라는 질문을 받았다고 생각해 봅시다. 아마 가장 무난하면서도 안정적으로 예측하는 방식은 지금의 기온과 같다고 답하는 것일 겁니다. 이러한 예측 방식은 과거의 기후 정보를 복잡하게 고려할 필요도 없이 간단하지만, 많은 경우에 실제로 꽤나 정확한 예측을 할 수 있는 방식입니다. 내일 낮 12시의 기온은 특이한 경우가 아니라면, 오늘 낮 12시의 기온과 거의 비슷할 것입니다.\n","\n","### <font color='red'>[TODO] 코드 구현</font>\n","\n","아래의 `eval_baseline` 함수는 베이스라인 모델의 평균 loss를 측정하는 함수입니다. 다음을 읽고 코드를 완성해보세요.\n","\n","1. 우리의 베이스라인은 현재 기온을 24시간 후의 기온으로 예측하는 방식입니다. 현재 기후 정보는 `test_dataset`에서 받은 `sequences`의 가장 마지막 타임스텝에 담겨있습니다. 입력으로 주는 `sequences`는 기온 뿐만 아니라 총 9가지 속성이 포함된 것임에 유의하세요. 기온은 9가지 속성중 가장 첫번째에 위치하고 있음을 염두에 두고 `sequences`로 부터 현재 \"기온\"을 가져와 `predictions` 변수에 저장하세요.\n","2. `loss_fn` 은 차후에 넣을 손실함수(loss function)입니다. `loss_fn` 함수의 첫번째 인자로 추정치인 `predictions`, 두번째 인자로 실제 24시간 이후의 기온인 `targets`을 이용하여 측정된 loss를 `loss` 변수에 저장하세요. (힌트: `loss_fn`는 함수 타입을 넣을 것임으로 다음과 같이 사용할 수 있습니다. <br> `함수(1번 인자, 2번인자, ...)`)\n","\n","**eval_baseline 함수 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"QUoDiCYhSKCr","colab_type":"code","colab":{}},"source":["def eval_baseline(dataset, loss_fn):\n","    mean_loss = tf.keras.metrics.Mean(\"mean_loss\")\n","    for sequences, targets in dataset:\n","        ## 코드 시작 ##\n","        predictions = sequences[:, -1, 0]    # 위의 설명 1. 을 참고하여 None을 채우세요.\n","        loss = loss_fn(predictions, targets)          # 위의 설명 2. 를 참고하여 None을 채우세요.\n","        ## 코드 종료 ##\n","        mean_loss(loss)\n","        \n","    print('Baseline Average Loss: {:.4f}'.format(mean_loss.result()))\n","    return mean_loss.result()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ZM6sIYnSKCu","colab_type":"text"},"source":["베이스라인의 성능을 측정합니다. 다음과 같은 결과가 출력된다면 성공적으로 구현한 것입니다.\n","\n","> Baseline Average Loss: 0.0993"]},{"cell_type":"code","metadata":{"id":"nEeg-GleSKCv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"47fd7e51-aae2-4265-c909-d25e91445609","executionInfo":{"status":"ok","timestamp":1579281416632,"user_tz":-540,"elapsed":8063,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["loss_object = tf.keras.losses.MeanSquaredError()\n","baseline_loss = eval_baseline(test_dataset, loss_object)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Baseline Average Loss: 0.0993\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DGFZGrj-SKCy","colab_type":"text"},"source":["평균 loss만 봐서는 베이스라인이 어느 정도로 예측을 잘하는지 감이 잘 오지 않습니다. 베이스라인 모델의 예측 기온과 실제 기온을 몇가지 살펴보면 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"SQSWh3wOSKCz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"446e37c8-986a-44b9-817c-92883776e06c","executionInfo":{"status":"ok","timestamp":1579281416633,"user_tz":-540,"elapsed":8051,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["for i in range(10):\n","    data_idx = np.random.randint(len(test_sequences))\n","    pred = test_sequences[data_idx, -1, 0]\n","    # 예측 기온을 normalization 이전 상태(섭씨 단위)로 되돌리는 작업\n","    pred = pred * train_std[0] + train_mean[0]\n","    # 실제 기온을 normalization 이전 상태(섭씨 단위)로 되돌리는 작업\n","    target = test_labels[data_idx] * train_std[0] + train_mean[0]\n","    print('예측 기온: {:.1f} / 실제 기온: {:.1f} / 차이: {:.1f}'.format(\n","        pred, target, pred - target))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["예측 기온: 15.0 / 실제 기온: 14.8 / 차이: 0.2\n","예측 기온: 4.9 / 실제 기온: -1.6 / 차이: 6.5\n","예측 기온: 21.0 / 실제 기온: 22.2 / 차이: -1.2\n","예측 기온: 12.7 / 실제 기온: 9.8 / 차이: 2.9\n","예측 기온: 16.1 / 실제 기온: 22.2 / 차이: -6.1\n","예측 기온: 31.5 / 실제 기온: 32.1 / 차이: -0.6\n","예측 기온: 0.5 / 실제 기온: -6.4 / 차이: 6.9\n","예측 기온: 3.8 / 실제 기온: 8.3 / 차이: -4.5\n","예측 기온: 19.8 / 실제 기온: 22.8 / 차이: -3.0\n","예측 기온: -2.1 / 실제 기온: -5.7 / 차이: 3.6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DpH9KbfxSKC0","colab_type":"text"},"source":["## 7. 네트워크 설계\n","\n","우리는 LSTM 구조를 통해 기온 예측을 모델을 학습시킬 것입니다. 설계할 네트워크의 대략적인 개요는 아래 그림과 같습니다.\n","\n","<img src=\"http://drive.google.com/uc?export=view&id=1AjxdDivdX23DSdubayKhAAcXmWfRBSvb\"  width=\"800px\" height=\"400px\" />\n","\n","LSTM의 매 타임스텝의 입력은 매 시간마다 기록된 9가지 속성값이 들어가게 됩니다. 그리고 마지막 타입스텝의 출력을 마무리로 Dense 레이어에 넣어 최종 예측 기온값을 출력하는 구조입니다.  \n","\n","### <font color='red'>[TODO] 코드 구현</font>\n","\n","우리가 구현할 클래스는 `SimpleLSTM`입니다. 다음을 읽고 코드를 완성해보세요.\n","\n","1. [`tf.keras.layers.CuDNNLSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/CuDNNLSTM) 또는 [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)을 사용하여 모델을 만들어보세요.\n","    - 만약 여러분이 GPU를 가지고 계시다면 `CuDNNLSTM` 아니라면 `LSTM`을 사용하시면 됩니다.\n","    - `tf.test.is_gpu_available()`를 사용하시면 GPU 사용이 가능한지 알 수 있습니다.\n","    - 첫번째 코드를 실행하면 GPU 보유에 따라서 해당하는 LSTM 층 함수를 `rnn_layer` 변수에 할당하게 됩니다.\n","2. 생성자의 파라미터 `hidden_sizes`는 우리가 설계할 LSTM 레이어의 hidden state의 크기입니다. 이 크기를 얼마를 할지는 역시 설계자의 몫입니다. `hidden_sizes`는 리스트로 값을 받습니다. 예를 들어 `hidden_sizes = [4, 8, 16]` 이면 첫 번째 layer의 `units=4`, 두 번째 layer의 `units=8`, 세 번째 layer의 `units=16` 입니다.\n","    -  **<2. 하이퍼파라미터 세팅>** 에서 우리는 첫 번째 layer의 `units=100`, 두 번째 layer의 `units=100`으로 하였습니다.\n","    - `self.hidden_size` 에 `hidden_sizes` 를 대입하세요.\n","3. `self.num_layers` 는 출력을 포함한 RNN 층의 개수 입니다. 즉, `hidden_sizes` 리스트의 길이가 됩니다.\n","4. `self.rnn` 에 `rnn_layer` 를 넣어서 RNN 층을 구성하세요! 먼저 첫번째부터 마지막 이전 층까지 for 문을 통해 층을 쌓고(stack), 마지막층은 따로 쌓을 것입니다.\n","    - rnn_layer의 첫번째 인자는 히든 뉴런의 수입니다. 또한 여러 층으로 쌓고 싶다면 `rnn_layer`의 인자   `return_sequences=True` 를 꼭 해주어야 합니다.\n","    - 맨 마지막 층의 `rnn_layer`의 최종 state를 가지고 `dense` 연산을 할 것 입니다. 따라서 맨 마지막은 `outputs` 값으로 모든 sequence 정보가 필요 없습니다. `return_sequences=False` (default) 를 하시면 됩니다.\n","5. `self.rnn`에서 나온 최종 state를 `dense` 레이어에 연결합니다. 이때 [`layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)를 이용하면 됩니다. 우리는 \"기온\"이라는 하나의 실수를 예측할 것을 기억하세요!\n","6. 마지막으로 `call` 함수에서  `self.rnn`과 `self.dense`를 연결하여 마무리하면 됩니다.\n","\n","**모델 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"H9C7sQ-PSKC1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4cc19dbe-3e4a-41fd-9ca1-b8042a38193c","executionInfo":{"status":"ok","timestamp":1579281416633,"user_tz":-540,"elapsed":8016,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["# GPU 사용 가능한지 체크, 해당 블록은 실행만 하면 됩니다.\n","if tf.test.is_gpu_available():\n","    print(\"Using 'tf.keras.layers.CuDNNLSTM'\")\n","    rnn_layer = tf.keras.layers.CuDNNLSTM\n","else:\n","    print(\"Using `tf.keras.layers.LSTM`\")\n","    rnn_layer = tf.keras.layers.LSTM"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Using 'tf.keras.layers.CuDNNLSTM'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nW-nJsduSKC3","colab_type":"code","colab":{}},"source":["class SimpleLSTM(tf.keras.Model):\n","    def __init__(self, hidden_sizes):\n","        super(SimpleLSTM, self).__init__()\n","        assert isinstance(hidden_sizes, list)\n","        ## 코드 시작 ##\n","        self.hidden_sizes = hidden_sizes    # 위의 설명 2. 를 참고하여 None을 채우세요.\n","        self.num_layers = len(hidden_sizes)      # 위의 설명 3. 을 참고하여 None을 채우세요.\n","        ## 코드 종료 ##\n","        \n","        # RNN 층 쌓기\n","        ## 코드 시작 ##\n","        self.rnn = []\n","        for i in range(self.num_layers-1):\n","            self.rnn.append(tf.keras.layers.CuDNNLSTM(self.hidden_sizes[i], return_sequences=True))   # 위의 설명 4. 를 참고하여 None을 채우세요.\n","        self.rnn.append(tf.keras.layers.CuDNNLSTM(self.hidden_sizes[self.num_layers-1], return_sequences=False))       # 위의 설명 4. 를 참고하여 None을 채우세요.\n","        ## 코드 종료 ##\n","        \n","        # Dense 층 만들기\n","        ## 코드 시작 ##\n","        self.dense = layers.Dense(1)           # 위의 설명 5. 를 참고하여 None을 채우세요.\n","        ## 코드 종료 ##\n","\n","    def call(self, x):\n","        # 입력 데이터인 x 가 RNN 층 > Dense 층 통과\n","        # 코드 시작\n","        for i in range(self.num_layers):\n","            x = self.rnn[i](x)                # RNN 층 통과: 위의 설명 6. 을 참고하여 None을 채우세요.\n","        x = self.dense(x)                    # Dense 층 통과: 위의 설명 6. 을 참고하여 None을 채우세요.\n","        ## 코드 종료 ##\n","\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uNK0UbxKSKC4","colab_type":"text"},"source":["아래의 코드 블록은 SimpleLSTM을 이용해서 모델을 생성해보고 데이터를 집어 넣어서 잘 동작하는지 확인해 보는 코드 입니다."]},{"cell_type":"code","metadata":{"id":"0SkGkL4wSKC4","colab_type":"code","colab":{}},"source":["model = SimpleLSTM(hidden_sizes)\n","for step, (sequences, targets) in enumerate(train_dataset.take(1)):\n","    predictions = model(sequences)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FuuGaICXSKC8","colab_type":"text"},"source":["`summary()` API로 모델이 잘 구성됐는지 확인해 봅니다."]},{"cell_type":"code","metadata":{"id":"J8_NUp3tSKC8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"3391ec1c-d6a3-42fb-83cc-42978f0aa537","executionInfo":{"status":"ok","timestamp":1579281418924,"user_tz":-540,"elapsed":10273,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["model.summary()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Model: \"simple_lstm\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","cu_dnnlstm (CuDNNLSTM)       multiple                  44400     \n","_________________________________________________________________\n","cu_dnnlstm_1 (CuDNNLSTM)     multiple                  80800     \n","_________________________________________________________________\n","dense (Dense)                multiple                  101       \n","=================================================================\n","Total params: 125,301\n","Trainable params: 125,301\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5xttOnqISKC-","colab_type":"text"},"source":["아래의 코드를 실행해 코드를 성공적으로 완성했는지 확인해보세요. \n","\n","별다른 문제가 없다면 이어서 진행하면 됩니다."]},{"cell_type":"code","metadata":{"id":"0hegkYoCSKC-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2a786d90-714e-4c66-f7f7-bc57798126d7","executionInfo":{"status":"ok","timestamp":1579281418925,"user_tz":-540,"elapsed":10263,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["checker.model_check(model)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["네트워를 잘 구현하셨습니다! 이어서 진행하셔도 좋습니다.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9yucR9zXSKC_","colab_type":"text"},"source":["## 8. Loss function, Optimizer 정의\n","\n","생성한 모델을 학습 시키기 위해서 손실함수를 정의해야 합니다. 뉴럴네트워크는 경사하강(gradient descent)방법을 이용하여 손실함수의 값을 줄이는 방향으로 파라미터를 갱신(update) 하게 됩니다. 또한 효과적인 경사하강 방법을 적용하기 위해 옵티마이져를 함께 사용할 겁니다.\n","\n","### <font color='red'>[TODO] 코드 구현</font>\n","\n","다음을 읽고 코드를 완성해보세요. \n","\n","1. 연속된 값을 예측하는 Regression 문제에서는 손실함수로 Mean Squared Error를 사용합니다. [`tf.keras.losses.MeanSquaredError()`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredError)를 만들고 `loss_object` 변수에 저장합니다.\n","2. 옵티마이저로 Adam optimizer를 사용하겠습니다. [`tf.train.AdamOptimizer()`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)를 `optimizer` 변수에 저장합니다. **<2. 하이퍼파라미터 세팅>** 에서 정의한 `learning_rate` 로 학습률을 지정해보세요!\n","\n","**이제 손실함수와 옵티마이저 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"tsoSr-R7SKDA","colab_type":"code","colab":{}},"source":["## 코드 시작 ##\n","loss_object = tf.keras.losses.MeanSquaredError()\n","optimizer = tf.train.AdamOptimizer(learning_rate)\n","## 코드 종료 ##\n","\n","# record loss for every epoch\n","mean_loss = tf.keras.metrics.Mean(\"loss\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-fo1MLISKDC","colab_type":"text"},"source":["아래의 코드를 실행해 코드를 성공적으로 완성했는지 확인해보세요. \n","\n","별다른 문제가 없다면 이어서 진행하면 됩니다."]},{"cell_type":"code","metadata":{"id":"RPlQ-dReSKDC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"31f73e27-69ac-4f29-e981-f66fa97dbbc1","executionInfo":{"status":"ok","timestamp":1579281418926,"user_tz":-540,"elapsed":10244,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["checker.loss_function_check(loss_object)\n","checker.optimizer_check(optimizer)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["MSE loss function을 잘 정의하셨습니다! 이어서 진행하셔도 좋습니다.\n","Adam optimizer를 잘 정의하셨습니다! 이어서 진행하셔도 좋습니다.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iIgpDx2XSKDE","colab_type":"text"},"source":["## 9. train, validation, test 함수 정의\n","\n","이번에는 훈련, 검증, 테스트를 진행하는 함수를 정의하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"qla_yNebSKDF","colab_type":"text"},"source":["### <font color='red'>[TODO] 코드 구현: 훈련 함수</font>\n","\n","먼저 훈련 함수입니다. 다음을 읽고 코드를 완성해 보세요.\n","\n","1 epoch 내에서 훈련을 진행하는 `train_step` 함수는 `model`, `sequences`와 `targets`를 인자로 받습니다.\n","\n","1. `predictions`: `model`에게 데이터를 입력하여 결과를 `predictions`로 저장합니다.\n","2. **<8. Loss function, Optimizer 정의>** 에서 정의한 `loss_object`를 이용하여 `targets`과 `predictions`의 손실값을 `loss_value`에 저장합니다.\n","    * `loss_object`의 인자로 사용될 `predictions`의 차원 수를 [`tf.squeeze`](https://www.tensorflow.org/api_docs/python/tf/squeeze)를 이용하여 맞춰줘야 합니다. squeeze함수는 1로 표현되는 차원을 제거 합니다.\n","3. `tape`로 정의된 [`tf.GradientTape()`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) 객체의 `gradient` 메서드를 이용하여 `loss_value`를 `model.trainable_variables`로 미분하고, 이 값을 `gradients` 변수에 저장합니다.\n","4. [`optimizer.apply_gradients()`](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer#methods)를 이용하여 파라미터를 업데이트 합니다. 함수 인자로 `gradients`와 `model.trainable_variables`를 zip으로 묶어서 전달하면 됩니다.\n","  \n","### Define training one step function\n","\n","**train_step 함수 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"c4Usta1CSKDF","colab_type":"code","colab":{}},"source":["def train_step(model, sequences, targets):\n","    ## 코드 시작 ##\n","    with tf.GradientTape() as tape:\n","        predictions = model(sequences)    # 위의 설명 1. 을 참고하여 None을 채우세요.\n","        loss_value = loss_object(y_true=targets, y_pred=tf.squeeze(predictions))     # 위의 설명 2. 를 참고하여 None을 채우세요.\n","\n","    gradients = tape.gradient(loss_value, model.trainable_variables)                # 위의 설명 3. 을 참고하여 None을 채우세요.\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # 위의 설명 4. 를 참고하여 None을 채우세요.\n","    ## 코드 종료 ##\n","\n","    return loss_value"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wUZTcAQXSKDG","colab_type":"text"},"source":["### Define validation and test functions\n","\n","### <font color='red'>[TODO] 코드 구현: 검증 함수</font>\n","\n","검증 함수입니다. 다음을 읽고 코드를 완성해 보세요.\n","\n","검증 과정에서는 파라미터 업데이트를 하지 않기 때문에 gradients를 계산할 필요가 없습니다. 일정한 에폭마다 검증 데이터인 `val_dataset` 을 이용하여 검증을 수행합니다. 모델 검증을 수행했을 때, 만약 검증 과정의 평균 loss가 현재까지 가장 낮다면 가장 잘 훈련된 모델로 가정하고 그때까지 학습한 모델을 저장합니다. 저장은 추후에 구현할 `save_model` 함수가 수행합니다.\n","\n","`validation` 함수는 `model`, `val_dataset`와 `epoch`을 인자로 받습니다.\n","1. `predictions`: `model`에게 데이터를 입력한 결과를 `predictions`에 저장합니다.\n","2. **<8. Loss function, Optimizer 정의>** 에서 정의한 `loss_object`를 이용하여 loss를 구합니다. (`targets`와 `predictions` 필요)\n","    * `loss_object`의 인자로 사용될 `predictions`의 차원 수를 [tf.squeeze](https://www.tensorflow.org/api_docs/python/tf/squeeze)를 이용하여 맞춰주는 것도 잊지 마세요.\n","    \n","**validation 함수 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"t9ZABDwOSKDH","colab_type":"code","colab":{}},"source":["def validation(model, val_dataset, epoch):\n","    print('Start validation #{}'.format(epoch))\n","    val_mean_loss = tf.keras.metrics.Mean(\"val_loss\")\n","\n","    for sequences, targets in val_dataset:\n","        ## 코드 시작 ##\n","        predictions = model(sequences)    # 위의 설명 1. 을 참고하여 None을 채우세요.\n","        val_loss_value = loss_object(y_true=targets, y_pred=tf.squeeze(predictions))\n","        ## 코드 종료 ##\n","        \n","        val_mean_loss(val_loss_value)\n","\n","    print('Validation #{} epoch  Average Loss: {:.4g}\\n'.format(\n","        epoch, val_mean_loss.result()))\n","\n","    return val_mean_loss.result()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lOtIKiaDSKDI","colab_type":"text"},"source":["### <font color='red'>[TODO] 코드 구현: 테스트 함수</font>\n","\n","테스트 함수입니다. 다음을 읽고 코드를 완성해 보세요.\n","\n","1. `predictions`: `model`에게 데이터를 입력한 결과를 `predictions`에 저장합니다.\n","2. **<8. Loss function, Optimizer 정의>** 에서 정의한 `loss_object`를 이용하여 loss를 구합니다. (`targets`와 `predictions` 필요)\n","    * `loss_object`의 인자로 사용될 `predictions`의 차원 수를 [tf.squeeze](https://www.tensorflow.org/api_docs/python/tf/squeeze)를 이용하여 맞춰주는 것도 잊지마세요.\n","    \n","`test`함수를 이용하여 베이스라인과 모델의 성능비교를 진행합니다.\n","\n","**test 함수 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"rboOEjW4SKDJ","colab_type":"code","colab":{}},"source":["def test(model, test_dataset, baseline_loss):\n","    print('Start test..')\n","    test_mean_loss = tf.keras.metrics.Mean(\"test_loss\")\n","\n","    for sequences, targets in test_dataset:\n","        ## 코드 시작 ##\n","        predictions = model(sequences)    # 위의 설명 1. 을 참고하여 None을 채우세요.\n","        test_loss_value = loss_object(y_true=targets, y_pred=tf.squeeze(predictions))\n","        ## 코드 종료 ##\n","        test_mean_loss(test_loss_value)\n","        \n","    print('BaseLine Loss {:.4g}'.format(baseline_loss.numpy()))\n","    print('Test Average Loss: {:.4g}'.format(test_mean_loss.result()))\n","\n","    if test_mean_loss.result().numpy() < baseline_loss:\n","        print('베이스라인 성능을 뛰어 넘었습니다!')\n","    else:\n","        print('아쉽지만 베이스라인 성능을 넘지 못했습니다.')\n","\n","    return test_mean_loss.result()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p3V9jAdRSKDL","colab_type":"text"},"source":["### 모델 저장 함수 정의\n","\n","다음 코드는 `train_dir` 폴더에 모델을 저장하는 함수 `save_model` 입니다."]},{"cell_type":"code","metadata":{"id":"qeW6OAcwSKDL","colab_type":"code","colab":{}},"source":["def save_model(model, epoch, train_dir):\n","    model_name = 'my_model_' + str(epoch)\n","    model.save_weights(os.path.join(train_dir, model_name))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPZlF2QKSKDN","colab_type":"text"},"source":["## 10. Training\n","\n","`train_step` 함수를 통해 학습을 진행합니다. LSTM과 같은 recurrent layer는 타임스텝을 따라 계산이 순차적으로 진행되기 때문에 상대적으로 학습 시간이 많이 소요됩니다. 따라서 시간 여유가 없는 분들은 모델 학습이 적당히 진행된다는 정도만 확인하고 다음 단계로 넘어가셔도 됩니다.\n","\n","만약 한 에폭 이상이 지나도록 loss가 전혀 감소하는 기미가 보이지 않는다면 이전의 구현에 문제가 있을 가능성이 높으니 코드를 다시 검토해주시기 바랍니다. 이러한 경우에는 구현한 `train_step` 함수를 다시 한 번 확인하시기 바랍니다. \n","\n","또한, 모델 저장 코드를 제대로 구현했다면 첫 에폭 학습후에 `train_dir` 경로에 `my_model_{}.data` 파일이 저장되어 있어야 합니다. 만약에 파일이 존재하지 않는다면 모델 저장 코드를 다시 확인하시기 바랍니다.\n","\n","`val_epoch`은 검증을 몇 에폭마다 진행할지 정하는 변수입니다. `print_steps` 는 훈련 과정의 출력 정도를 관장하는 변수입니다. 작으면 작을 수록 자주 출력하게 됩니다. 원하는 만큼 조절해보시길 바랍니다."]},{"cell_type":"code","metadata":{"id":"8frU4wxJSKDN","colab_type":"code","colab":{}},"source":["train_dir = os.path.join('./train/exp1')\n","print_steps = 30\n","val_epoch = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3GZUe1BSKDP","colab_type":"text"},"source":["### <font color='red'>[TODO] 코드 구현: main 함수</font>\n","\n","이전에 정의한 `train_step`, `validation` 함수를 사용하여 전체 훈련을 진행하는 `main` 함수 코드를 작성합니다. 전체 프로세스는 다음과 같습니다.\n","\n","* `max_epochs` 동안 훈련하는데 아래 과정을 반복합니다.\n","    * `train_dataset` 에서 미니배치 데이터와 라벨을 가져옵니다.\n","    * `train_step` 함수를 통해 훈련합니다.\n","    * `validation` 함수를 통해 모델을 검증합니다. 분류 성능이 이전 단계보다 좋다면 저장하게 됩니다. \n","\n","**main 함수 코드를 작성해보세요! \"<font color='45A07A'>## 코드 시작 ##</font>\"과 \"<font color='45A07A'>## 코드 종료 ##</font>\" 사이의 <font color='075D37'>None</font> 부분을 채우시면 됩니다.**"]},{"cell_type":"code","metadata":{"id":"lNue7ZGoSKDQ","colab_type":"code","colab":{}},"source":["def main(model, train_dataset, val_dataset, val_epoch, print_steps, save_dir):\n","    print('Start training..')\n","    num_batches_per_epoch = len(list(train_dataset))\n","    global_step = 0\n","    best_loss = 999999.\n","\n","    for epoch in range(max_epochs):\n","        for step, (sequences, targets) in enumerate(train_dataset):\n","\n","            start_time = time.time()\n","            # train_step 함수 사용하여 loss 구하기\n","            ## 코드 시작 ##\n","            loss_value = train_step(model, sequences, targets)\n","            ## 코드 종료 ##\n","            mean_loss(loss_value)\n","            global_step += 1\n","\n","            if global_step % print_steps == 0:\n","                duration = time.time() - start_time\n","                examples_per_sec = batch_size / float(duration)\n","                clear_output(wait=True)\n","                print(\"Epochs: [{}/{}] step: [{}/{}] loss: {:.4g}  ({:.2f} examples/sec; {:.3f} sec/batch)\".format(\n","                    epoch+1, max_epochs, step+1, num_batches_per_epoch,\n","                    mean_loss.result(), examples_per_sec, duration))\n","\n","            mean_loss.reset_states()\n","\n","        if (epoch + 1) % val_epoch == 0:\n","            # validation 함수 사용하여 검증하기\n","            # 여기서 epoch는 0부터 시작하기 때문에 + 1 을 해주시길 바랍니다.\n","            ## 코드 시작 ##\n","            val_mean_loss = validation(model, val_dataset, epoch)\n","            ## 코드종료 ##\n","            if val_mean_loss < best_loss:\n","                print('Best performance at epoch: {}'.format(epoch + 1))\n","                print('Save in {}\\n'.format(save_dir))\n","                best_loss = val_mean_loss\n","                save_model(model, epoch+1, save_dir)\n","\n","    print('training done..')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K9Q0yncrSKDR","colab_type":"text"},"source":["다음 코드를 통해 모델 훈련을 시작하세요! CPU만을 사용한 학습일 경우 굉장히 오랜 시간이 걸립니다."]},{"cell_type":"code","metadata":{"id":"57NXg_Q5SKDS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"b4b561b2-1f7c-4af2-a617-8d7ef2fbe82c","executionInfo":{"status":"ok","timestamp":1579281677457,"user_tz":-540,"elapsed":620,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["main(model, train_dataset, val_dataset, val_epoch, print_steps, save_dir=train_dir)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Epochs: [30/30] step: [109/109] loss: 0.07774  (1954.77 examples/sec; 0.065 sec/batch)\n","Start validation #29\n","Validation #29 epoch  Average Loss: 0.06757\n","\n","Best performance at epoch: 30\n","Save in ./train/exp1\n","\n","training done..\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6pVe9mQjSKDT","colab_type":"text"},"source":["## 11. 저장된 모델 불러오기 및 test\n","\n","학습한 모델의 성능을 테스트합니다. 저장한 모델 파일을 `model.load_weights()`를 통하여 불러올 수 있습니다. 모델의 저장 및 불러오기를 좀 더 자세히 알고 싶으면 [Save and restore](https://www.tensorflow.org/guide/keras#save_and_restore) 문서를 참고하세요. 위에서 학습을 끝까지 진행하지 않았다면, 첫번째 주석 처리된 부분을 주석 해제하여, 제공해드린 미리 학습시킨 모델을 불러올 수 있습니다. "]},{"cell_type":"code","metadata":{"id":"0JnHPVZJSKDU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"691938a3-94e3-4a05-b0c5-b3fe22dc0bf9","executionInfo":{"status":"ok","timestamp":1579281677776,"user_tz":-540,"elapsed":269011,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["# train_dir = './train/pretrained' # 모델 학습을 끝까지 진행하지 않은 경우에 사용\n","\n","# 아래의 모델 불러오기를 정확히 구현했는지 확인하기 위해 새로 모델을 선언하여 학습 이전 상태로 초기화\n","model = SimpleLSTM(hidden_sizes)  \n","# inputs을 넣어 모델 생성\n","for sequences, targets in train_dataset.take(1):\n","    outputs = model(sequences)\n","# 모델 파라미터 불러오기\n","model.load_weights(tf.train.latest_checkpoint(train_dir))"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0ce1ea3438>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"4EopnQ6WSKDW","colab_type":"text"},"source":["마지막으로 모델의 성능을 테스트합니다. 베이스라인 성능을 뛰어 넘었다는 문구가 나오면 성공적으로 진행한 것입니다. "]},{"cell_type":"code","metadata":{"id":"g8fcTsJ9SKDZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"b0df737b-c241-4c83-f9d6-423d3344c8b9","executionInfo":{"status":"ok","timestamp":1579281677777,"user_tz":-540,"elapsed":269002,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["test_acc_value = test(model, test_dataset, baseline_loss)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Start test..\n","BaseLine Loss 0.09927\n","Test Average Loss: 0.08346\n","베이스라인 성능을 뛰어 넘었습니다!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6BKaZJLxSKDa","colab_type":"text"},"source":["학습된 모델의 예측 기온과 실제 기온을 몇가지 살펴보면 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"XGN0kqmjSKDb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"1a874cfa-1dbb-4f3e-c0c3-f6c0f6d5ca6a","executionInfo":{"status":"ok","timestamp":1579281678362,"user_tz":-540,"elapsed":269579,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["for i in range(10):\n","    data_idx = np.random.randint(len(test_sequences))\n","    pred = model(test_sequences[data_idx:data_idx+1, :, :]).numpy()[0, 0]\n","    # 예측 기온을 normalization 이전 상태(섭씨 단위)로 되돌리는 작업\n","    pred = pred * train_std[0] + train_mean[0]\n","    # 실제 기온을 normalization 이전 상태(섭씨 단위)로 되돌리는 작업\n","    target = test_labels[data_idx] * train_std[0] + train_mean[0]\n","    print('예측 기온: {:.1f} / 실제 기온: {:.1f} / 차이: {:.1f}'.format(\n","        pred, target, pred - target))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["예측 기온: 26.7 / 실제 기온: 29.4 / 차이: -2.7\n","예측 기온: 23.4 / 실제 기온: 24.1 / 차이: -0.7\n","예측 기온: 26.1 / 실제 기온: 25.2 / 차이: 0.9\n","예측 기온: 23.9 / 실제 기온: 27.2 / 차이: -3.3\n","예측 기온: 28.9 / 실제 기온: 30.6 / 차이: -1.7\n","예측 기온: -0.2 / 실제 기온: 0.6 / 차이: -0.8\n","예측 기온: 7.8 / 실제 기온: 6.9 / 차이: 0.9\n","예측 기온: -4.5 / 실제 기온: -10.4 / 차이: 5.9\n","예측 기온: 23.8 / 실제 기온: 22.2 / 차이: 1.6\n","예측 기온: 19.9 / 실제 기온: 18.5 / 차이: 1.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rHCeoxaOSKDc","colab_type":"text"},"source":["어떠신가요? 잘 맞는것 같나요? 모델 구조의 은닉층 크기(`hidden_size`) 등 다양한 하이퍼파라미터를 조절해서 더 좋은 성능을 내는 모델을 만들어보세요!"]},{"cell_type":"markdown","metadata":{"id":"w6p-ZN6-SKDc","colab_type":"text"},"source":["## 12. Summary\n","\n","이로써 마지막 RNN 프로젝트를 완료했습니다. 고생하셨습니다! \n","\n","우리는 이번 실습을 통해 다음과 같은 내용을 학습했습니다.\n","- 날씨와 같은 시계열 정보를 다룰 수 있다.\n","- RNN을 설계하고 시간 순서상 미래의 정보를 예측하는 모델을 학습시킬 수 있다.\n","- 상식적인 수준의 베이스라인을 도입하여 학습한 모델의 성능을 검증할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"PfcAUn89SKDd","colab_type":"text"},"source":["# Self-Review\n","\n","학습 환경에 맞춰 알맞는 제출방법을 실행하세요!\n","\n","### 로컬 환경 실행자\n","\n","1. 모든 실습 완료 후, Jupyter Notebook 을 `Ctrl+S` 혹은 `File > Save and checkpoint`로 저장합니다.\n","2. 제일 하단의 코드를 실행합니다. 주의할 점은 Jupyter Notebook 의 파일이름을 수정하시면 안됩니다! 만약에 노트북 이름을 수정했다면 \"tensorflow-rnn-project\" 로 바꿔주시길 바랍니다. 모든 평가 기준을 통과하면, 함수 실행 후 프로젝트 \"submit\" 디렉토리와 압축된 \"submit.zip\"이 생깁니다. \"cnn_submission.tsv\" 파일을 열고 모두 Pass 했는지 확인해보세요!\n","    * \"rnn_submission.tsv\" : 평가 기준표에 근거해 각 세부항목의 통과여부(Pass/Fail) 파일\n","    * \"rnn_submission.html\" : 여러분이 작성한 Jupyter Notebook 을 html 형식으로 전환한 파일\n","3. 코드 실행결과 안내에 따라서 `submit.zip` 파일을 확인하시고 제출해주시길 바랍니다.\n","\n","### Colab 환경 실행자\n","\n","1. 모든 실습 완료 후, Jupyter Notebook 을 `Ctrl+S` 로 저장합니다.\n","2. 제일 하단의 코드를 실행합니다. 코드 실행결과 안내에 따라서 재작성하거나 다음스텝으로 넘어갑니다. 모든 평가 기준을 통과하면, 함수 실행 후 프로젝트 \"submit\" 디렉토리와 압축된 \"rnn_submission.tsv\"만 생깁니다. \"rnn_submission.tsv\" 파일을 열고 모두 Pass 했는지 확인해보세요!\n","    * \"rnn_submission.tsv\" : 평가 기준표에 근거해 각 세부항목의 통과여부(Pass/Fail) 파일\n","3. 프로젝트를 저장한 드라이브의 `submit` 폴더에서 `rnn_submission.tsv` 파일을 다운 받습니다.\n","4. Colab Notebook 에서 `파일 > .ipynb 다운로드` 를 통해서 노트북을 다운로드 받습니다.\n","5. 로컬에서 Jupyter Notebook 프로그램을 실행시킵니다. \n","6. 4번 스텝에서 다운받은 노트북을 열고 `File > Download as > HTML(.html)` 로 재 다운로드 합니다.\n","7. 3번 스텝에서 받은 파일과 6번 스텝에서 받은 파일을 하나의 폴더에 넣고, `submit.zip` 이라는 이름으로 압축하고 제출해주시길 바랍니다."]},{"cell_type":"code","metadata":{"id":"lyM-s1nKSKDd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"8450761c-431c-4a6c-ec17-1e6f0b4dade2","executionInfo":{"status":"ok","timestamp":1579281680220,"user_tz":-540,"elapsed":271434,"user":{"displayName":"HONGYEOB KIM","photoUrl":"","userId":"17352177631675721232"}}},"source":["import check_util.submit as submit\n","submit.process_submit()"],"execution_count":37,"outputs":[{"output_type":"stream","text":["[ Self-Check ] 시스템: Linux\n","[ Self-Check ] Submit 파일 생성완료! 위치: 'submit'\n","[ Self-Check ] submit.zip 생성 완료!\n","[ Self-Check ] 모든 평가기준을 통과했습니다. 압축파일을 제출해주세요!\n"],"name":"stdout"}]}]}